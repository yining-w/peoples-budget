x))})
# Apply it for substituting the regular expression given in one of the former answers by " "
docs<- tm_map(docs,toSpace,"[^[:graph:]]")
# the tolower transformation worked!
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("english"))
##Determine frequency
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix),decreasing=TRUE)
wordcloud <- data.frame(word = names(words),freq=words)
set.seed(1234) # for reproducibility
wordcloud(words = wordcloud$word, freq = wordcloud$freq, min.freq = 1, max.words=200, random.order=FALSE, rot.per=0.35,            colors=brewer.pal(8, "Dark2"))
wordcloud(words = wordcloud$word, freq = wordcloud$freq, min.freq = 1, max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Spectral"))
wordcloud(words = wordcloud$word, freq = wordcloud$freq, min.freq = 1, max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Set1"))
ggsave("whiteboardraw.png")
whiteboard_two <- read.delim("whiteboard.txt")
docs <- Corpus(VectorSource(whiteboard_two))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation)# %>%
##make all the words lower case
toSpace <- content_transformer(function(x, pattern) {return (gsub(pattern," ",
x))})
# Apply it for substituting the regular expression given in one of the former answers by " "
docs<- tm_map(docs,toSpace,"[^[:graph:]]")
docs <- tm_map(docs, content_transformer(tolower))
#remove stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
##Determine frequency
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix),decreasing=TRUE)
wordcloud <- data.frame(word = names(words),freq=words)
set.seed(1234) # for reproducibility
set.seed(1234) # for reproducibility
wordcloud(words = wordcloud$word, freq = wordcloud$freq, min.freq = 1, max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Set1"))
ggsave("whiteboardgrouped.png")
whiteboard <- read.csv("whiteboard.csv")
text <- whiteboard$transcription
docs <- Corpus(VectorSource(text))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation)# %>%
##make all the words lower case
toSpace <- content_transformer(function(x, pattern) {return (gsub(pattern," ",
x))})
# Apply it for substituting the regular expression given in one of the former answers by " "
docs<- tm_map(docs,toSpace,"[^[:graph:]]")
docs <- tm_map(docs, content_transformer(tolower))
#remove stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
##Determine frequency
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix),decreasing=TRUE)
wordcloud <- data.frame(word = names(words),freq=words)
##Generate the word cloud
set.seed(1234) # for reproducibility
wordcloud(words = wordcloud$word, freq = wordcloud$freq, min.freq = 1, max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Set1"))
##Save it
ggsave("whiteboardraw.png")
##Save it
ggsave("whiteboardraw.png")
wordcloud(words = wordcloud$word, freq = wordcloud$freq, min.freq = 1, max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Set1"))
install.packages("webshot")
library(webshot)
knitr::opts_chunk$set(echo = TRUE)
library(tm)
library(wordcloud2)
library(wordcloud)
library(RColorBrewer)
library(webshot)
saveWidget(wordcloud,"wordcloudgrouped.html",selfcontained = F)
htmlwidgets::saveWidget(wordcloud,"wordcloudgrouped.html",selfcontained = F)
htmlwidgets::saveWidget(as_widget(wordcloud),"wordcloudgrouped.html",selfcontained = F)
png("cloud_grouped", width = 480, height = 480)
comparison.cloud(document_tm_clean_mat_s, max.words=500, random.order=FALSE,c(4,0.4), title.size=1.4)
cloud 2 = wordcloud(words = wordcloud$word, freq = wordcloud$freq, min.freq = 1, max.words=200, random.order=FALSE, rot.per=0.35,
cloud_two = wordcloud(words = wordcloud$word, freq = wordcloud$freq, min.freq = 1, max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Set1"))
png("cloud_grouped", width = 480, height = 480)
comparison.cloud(cloud_two, max.words=500, random.order=FALSE,c(4,0.4), title.size=1.4)
htmlwidgets::saveWidget(as_widget(cloud_two),"wordcloudgrouped.html",selfcontained = F)
htmlwidgets::saveWidget(cloud_two,"wordcloudgrouped.html",selfcontained = F)
comparison.cloud(cloud_two, max.words=500, random.order=FALSE,c(4,0.4), title.size=1.4)
dev.off()
cloud_two = wordcloud(words = wordcloud$word, freq = wordcloud$freq, min.freq = 1, max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Set1"))
saveWidget(wordcloud_two, file="mywordcloud.html")
png("wordcloud_packages.png", width=1280,height=800)
cloud_two = wordcloud(words = wordcloud$word, freq = wordcloud$freq, min.freq = 1, max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Set1"))
dev.off()
barplot(d[1:10,]$freq, las = 2, names.arg = d[1:10,]$word,
col ="lightblue", main ="Most frequent words",
ylab = "Word frequencies")
barplot(wordcloud[1:10,]$freq, las = 2, names.arg = wordcloud[1:10,]$word,
col ="lightblue", main ="Most frequent words",
ylab = "Word frequencies")
##most frequent words
barplot(wordcloud[1:10,]$freq, las = 2, names.arg = wordcloud[1:10,]$word,
col ="deepskyblue", main ="Most frequent words",
ylab = "Word frequencies")
##most frequent words
barplot(wordcloud[1:10,]$freq, las = 2, names.arg = wordcloud[1:10,]$word,
fill = "blue", main ="Most frequent words",
ylab = "Word frequencies")
##most frequent words
barplot(wordcloud[1:10,]$freq, las = 2, names.arg = wordcloud[1:10,]$word,
col = "blue", main ="Most frequent words",
ylab = "Word frequencies")
##most frequent words
barplot(wordcloud[1:10,]$freq, las = 2, names.arg = wordcloud[1:10,]$word,
col = "maroon4", main ="Most frequent words",
ylab = "Word frequencies")
wordcloud(words = wordcloud$word, freq = wordcloud$freq, min.freq = 1, max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Set1"))
whiteboard <- read.csv("whiteboard.csv")
text <- whiteboard$transcription
docs <- Corpus(VectorSource(text))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation)# %>%
##make all the words lower case
toSpace <- content_transformer(function(x, pattern) {return (gsub(pattern," ",
x))})
# Apply it for substituting the regular expression given in one of the former answers by " "
docs<- tm_map(docs,toSpace,"[^[:graph:]]")
docs <- tm_map(docs, content_transformer(tolower))
#remove stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
##Determine frequency
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix),decreasing=TRUE)
wordcloud <- data.frame(word = names(words),freq=words)
barplot(wordcloud[1:10,]$freq, las = 2, names.arg = wordcloud[1:10,]$word,
col = "maroon4", main ="Most frequent words",
ylab = "Word frequencies")
barplot(wordcloud[1:10,]$freq, las = 2, names.arg = wordcloud[1:10,]$word,
col = "maroon4", main ="Most frequent words",
ylab = "Count")
##With Some manual cleaning, basically removing sentences to key words**
whiteboard_two <- read.delim("whiteboard.txt")
docs <- Corpus(VectorSource(whiteboard_two))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation)# %>%
##make all the words lower case
toSpace <- content_transformer(function(x, pattern) {return (gsub(pattern," ",
x))})
# Apply it for substituting the regular expression given in one of the former answers by " "
docs<- tm_map(docs,toSpace,"[^[:graph:]]")
docs <- tm_map(docs, content_transformer(tolower))
#remove stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
##Determine frequency
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix),decreasing=TRUE)
wordcloud <- data.frame(word = names(words),freq=words)
set.seed(1234) # for reproducibility
png("wordcloud_packages.png", width=1280,height=800)
wordcloud(words = wordcloud$word, freq = wordcloud$freq, min.freq = 1, max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Set1"))
wordcloud(words = wordcloud$word, freq = wordcloud$freq, min.freq = 1, max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Set1"))
##most frequent words
barplot(wordcloud[1:10,]$freq, las = 2, names.arg = wordcloud[1:10,]$word,
col = "maroon4", main ="Most frequent words",
ylab = "Word frequencies")
whiteboard <- read.csv("whiteboard.csv")
text <- whiteboard$transcription
docs <- Corpus(VectorSource(text))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation)# %>%
##make all the words lower case
toSpace <- content_transformer(function(x, pattern) {return (gsub(pattern," ",
x))})
# Apply it for substituting the regular expression given in one of the former answers by " "
docs<- tm_map(docs,toSpace,"[^[:graph:]]")
docs <- tm_map(docs, content_transformer(tolower))
#remove stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
##Determine frequency
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix),decreasing=TRUE)
wordcloud <- data.frame(word = names(words),freq=words)
##Generate the word cloud
set.seed(1234) # for reproducibility
wordcloud(words = wordcloud$word, freq = wordcloud$freq, min.freq = 1, max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Set1"))
barplot(wordcloud[1:10,]$freq, las = 2, names.arg = wordcloud[1:10,]$word,
col = "maroon4", main ="Most frequent words",
ylab = "Count")
##Word cloud without some manual grouping
whiteboard <- read.csv("whiteboard.csv")
text <- whiteboard$transcription
docs <- Corpus(VectorSource(text))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation)# %>%
##make all the words lower case
toSpace <- content_transformer(function(x, pattern) {return (gsub(pattern," ",
x))})
# Apply it for substituting the regular expression given in one of the former answers by " "
docs<- tm_map(docs,toSpace,"[^[:graph:]]")
docs <- tm_map(docs, content_transformer(tolower))
#remove stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
##Determine frequency
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix),decreasing=TRUE)
wordcloud <- data.frame(word = names(words),freq=words)
##Generate the word cloud
set.seed(1234) # for reproducibility
wordcloud(words = wordcloud$word, freq = wordcloud$freq, min.freq = 1, max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Set1"))
barplot(wordcloud[1:10,]$freq, las = 2, names.arg = wordcloud[1:10,]$word,
col = "maroon4", main ="Most frequent words",
ylab = "Count")
##With Some manual cleaning, basically removing sentences to key words**
whiteboard_two <- read.delim("whiteboard.txt")
docs <- Corpus(VectorSource(whiteboard_two))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation)# %>%
##make all the words lower case
toSpace <- content_transformer(function(x, pattern) {return (gsub(pattern," ",
x))})
# Apply it for substituting the regular expression given in one of the former answers by " "
docs<- tm_map(docs,toSpace,"[^[:graph:]]")
docs <- tm_map(docs, content_transformer(tolower))
#remove stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
##Determine frequency
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix),decreasing=TRUE)
wordcloud <- data.frame(word = names(words),freq=words)
##most frequent words
barplot(wordcloud[1:10,]$freq, las = 2, names.arg = wordcloud[1:10,]$word,
col = "maroon4", main ="Most frequent words",
ylab = "Word frequencies")
##most frequent words
barplot(wordcloud[1:10,]$freq, las = 2, names.arg = wordcloud[1:10,]$word,
col = "maroon4", main ="Most frequent words",
ylab = "Count")
##most frequent words
barplot(wordcloud[1:10,]$freq, las = 2, names.arg = wordcloud[1:10,]$word,
col = "maroon4", main ="Most frequent words", size = "5"
ylab = "Count")
##most frequent words
barplot(wordcloud[1:10,]$freq, las = 2, names.arg = wordcloud[1:10,]$word,
col = "maroon4", main ="Most frequent words", size = "5",
ylab = "Count")
##most frequent words
wordcloud %>% ggplot() %>%
geom_bar(aes(x=freq))
##most frequent words
wordcloud %>% ggplot() + geom_bar(aes(x=freq))
##most frequent words
wordcloud %>% ggplot() + geom_bar(aes(x=word))
##most frequent words
barplot(wordcloud[1:10,]$freq, las = 2, names.arg = wordcloud[1:10,]$word,
col = "maroon4", main ="Most frequent words", size = "5",
ylab = "Count")
##most frequent words
barplot(wordcloud[1:10,]$freq, las = 2, names.arg = wordcloud[1:10,]$word,
col = "maroon4", main ="Most frequent words", size = "5",
ylab = "Count")
wordcloud(words = wordcloud$word, freq = wordcloud$freq, min.freq = 1, max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Set1"))
wordcloud(words = wordcloud$word, freq = wordcloud$freq, min.freq = 1, max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(7, "Set1"))
wordcloud(words = wordcloud$word, freq = wordcloud$freq, min.freq = 1, max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(7, "Spectral"))
wordcloud(words = wordcloud$word, freq = wordcloud$freq, min.freq = 1, max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(7, "Set3"))
wordcloud(words = wordcloud$word, freq = wordcloud$freq, min.freq = 1, max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(7, "Set2"))
whiteboard <- read.csv("whiteboard.csv")
text <- whiteboard$transcription
docs <- Corpus(VectorSource(text))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation)# %>%
##make all the words lower case
toSpace <- content_transformer(function(x, pattern) {return (gsub(pattern," ",
x))})
# Apply it for substituting the regular expression given in one of the former answers by " "
docs<- tm_map(docs,toSpace,"[^[:graph:]]")
docs <- tm_map(docs, content_transformer(tolower))
#remove stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
##Determine frequency
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix),decreasing=TRUE)
wordcloud <- data.frame(word = names(words),freq=words)
##Generate the word cloud
set.seed(1234) # for reproducibility
wordcloud(words = wordcloud$word, freq = wordcloud$freq, min.freq = 1, max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Set1"))
wordcloud(words = wordcloud$word, freq = wordcloud$freq, min.freq = 1, max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(7, "Set1"))
remove(list=ls())
library(formattable)
install.packages("formattable")
setwd("C:/Users/yinin/Desktop/CUE Project/Peoples Budget Findings/data clean")
budget <- readcsv("online_budgetallocations.csv")
budget <- read.csv("online_budgetallocations.csv")
formattable(budget, list(
age = color_tile("white", "orange"),
grade = formatter("span", style = x ~ ifelse(x == "A",
style(color = "green", font.weight = "bold"), NA)),
area(col = c(test1_score, test2_score)) ~ normalize_bar("pink", 0.2),
final_score = formatter("span",
style = x ~ style(color = ifelse(rank(-x) <= 3, "green", "gray")),
x ~ sprintf("%.2f (rank: %02d)", x, rank(-x))),
registered = formatter("span",
style = x ~ style(color = ifelse(x, "green", "red")),
x ~ icontext(ifelse(x, "ok", "remove"), ifelse(x, "Yes", "No")))
))```
formattable(budget, list(
age = color_tile("white", "orange"),
grade = formatter("span", style = x ~ ifelse(x == "A",
style(color = "green", font.weight = "bold"), NA)),
area(col = c(test1_score, test2_score)) ~ normalize_bar("pink", 0.2),
final_score = formatter("span",
style = x ~ style(color = ifelse(rank(-x) <= 3, "green", "gray")),
x ~ sprintf("%.2f (rank: %02d)", x, rank(-x)))
))
library(formattable)
remove(list=ls())
library(formattable)
budget <- read.csv("online_budgetallocations.csv")
formattable(budget, list(
age = color_tile("white", "orange"),
grade = formatter("span", style = x ~ ifelse(x == "A",
style(color = "green", font.weight = "bold"), NA)),
area(col = c(test1_score, test2_score)) ~ normalize_bar("pink", 0.2),
final_score = formatter("span",
style = x ~ style(color = ifelse(rank(-x) <= 3, "green", "gray")),
x ~ sprintf("%.2f (rank: %02d)", x, rank(-x)))
))
View(budget)
View(budget)
formattable(budget, list(
age = color_tile("white", "orange"),
grade = formatter("span", style = x ~ ifelse(x == "A",
style(color = "green", font.weight = "bold"), NA)),
area(col = c(Total_Respondents)) ~ normalize_bar("pink", 0.2),
final_score = formatter("span",
style = x ~ style(color = ifelse(rank(-x) <= 3, "green", "gray")),
x ~ sprintf("%.2f (rank: %02d)", x, rank(-x)))
))
formattable(budget, list(
age = color_tile("white", "orange"),
grade = formatter("span", style = x ~ ifelse(x == "A",
style(color = "green", font.weight = "bold"), NA)),
area(col = c(Total_Respondents, Carceral_Score, Community_Score, Education_Score, Health_Score, Housing_Score, Infrastructure)) ~ normalize_bar("pink", 0.2),
final_score = formatter("span",
style = x ~ style(color = ifelse(rank(-x) <= 3, "green", "gray")),
x ~ sprintf("%.2f (rank: %02d)", x, rank(-x)))
))
formattable(budget, list(
age = color_tile("white", "orange"),
grade = formatter("span", style = x ~ ifelse(x == "A",
style(color = "green", font.weight = "bold"), NA)),
area(col = c(Total_Respondents, Carceral_Score, Community_Score, Education_Score, Health_Score, Housing_Score, Infrastructure_Score)) ~ normalize_bar("pink", 0.2),
final_score = formatter("span",
style = x ~ style(color = ifelse(rank(-x) <= 3, "green", "gray")),
x ~ sprintf("%.2f (rank: %02d)", x, rank(-x)))
))
budget$Total_Respondents <- budget$Respondents
budget$Carceral_Score <- Carceral
budget$Carceral_Score <- budget$Carceral
budget$Community_Score <- budget$Community
budget$Health_Score <- budget$Health
budget$Housing_Score <- budget$Housing
budget$Infrastructure_Score <- budget$Infrastructure
formattable(budget, list(
Respondents = color_tile("orange"),
area(col = c(Respondents, Carceral, Community, Educatio, Health, Housing, Infrastructure)) ~ normalize_bar("pink", 0.2),
final_score = formatter("span",
style = x ~ style(color = ifelse(rank(-x) <= 3, "green", "gray")),
x ~ sprintf("%.2f (rank: %02d)", x, rank(-x)))
))
formattable(budget, list(
Respondents = color_tile("orange"),
area(col = c(Carceral, Community, Educatio, Health, Housing, Infrastructure)) ~ normalize_bar("pink", 0.2),
final_score = formatter("span",
style = x ~ style(color = ifelse(rank(-x) <= 3, "green", "gray")),
x ~ sprintf("%.2f (rank: %02d)", x, rank(-x)))
))
View(budget)
budget <- read.csv("online_budgetallocations.csv")
budget$Total_Respondents <- budget$Respondents
budget <- read.csv("online_budgetallocations.csv")
colnames(budget) = c("Respondents", "Community", "Education", "Health", "Housing", "Infrastructure")
formattable(budget, list(
Respondents = color_tile("orange"),
area(col = c(Carceral, Community, Education, Health, Housing, Infrastructure)) ~ normalize_bar("pink", 0.2),
final_score = formatter("span",
style = x ~ style(color = ifelse(rank(-x) <= 3, "green", "gray")),
x ~ sprintf("%.2f (rank: %02d)", x, rank(-x)))
))
formattable(budget, list(
Respondents = color_tile("orange"),
area(col = c(Carceral, Community, Education, Health, Housing, Infrastructure)) ~ normalize_bar("pink", 0.2)))
formattable(budget, list(
Respondents = color_tile("white", "orange"),
area(col = c(test1_score, test2_score)) ~ normalize_bar("pink", 0.2),
final_score = formatter("span",
style = x ~ style(color = ifelse(rank(-x) <= 3, "green", "gray")),
x ~ sprintf("%.2f (rank: %02d)", x, rank(-x))),
registered = formatter("span",
style = x ~ style(color = ifelse(x, "green", "red")),
x ~ icontext(ifelse(x, "ok", "remove"), ifelse(x, "Yes", "No")))
))
formattable(budget, list(
Respondents = color_tile("white", "orange"),
area(col = c(Carceral, Community, Education, Health, Housing, Infrastructure)) ~ normalize_bar("pink", 0.2),
final_score = formatter("span",
style = x ~ style(color = ifelse(rank(-x) <= 3, "green", "gray")),
x ~ sprintf("%.2f (rank: %02d)", x, rank(-x))),
registered = formatter("span",
style = x ~ style(color = ifelse(x, "green", "red")),
x ~ icontext(ifelse(x, "ok", "remove"), ifelse(x, "Yes", "No")))
))
View(budget)
budget <- read.csv("online_budgetallocations.csv")
colnames(budget) = c("Respondents", "Carceral", "Community", "Education", "Health", "Housing", "Infrastructure")
formattable(budget, list(
Respondents = color_tile("white", "orange"),
area(col = c(Carceral, Community, Education, Health, Housing, Infrastructure)) ~ normalize_bar("pink", 0.2),
final_score = formatter("span",
style = x ~ style(color = ifelse(rank(-x) <= 3, "green", "gray")),
x ~ sprintf("%.2f (rank: %02d)", x, rank(-x))),
registered = formatter("span",
style = x ~ style(color = ifelse(x, "green", "red")),
x ~ icontext(ifelse(x, "ok", "remove"), ifelse(x, "Yes", "No")))
))
## Including Plots
kbl(budget) %>%
kable_styling(bootstrap_options = c("striped", "hover"))
install.packages("kableExtra")
library(kableExtra)
## Including Plots
kbl(budget) %>%
kable_styling(bootstrap_options = c("striped", "hover"))
kbl(budget) %>%
kable_styling(bootstrap_options = c("striped", "hover"))
comm <- read.csv("summary_comm.csv")
geo <- read.csv("summary_geo.csv")
View(geo)
budget <- read.csv("online_budgetallocations.csv")
comm <- read.cssv("summary_comm.csv")
geo <- read.csv("summary_geo.csv")
ward <- read.csv("summary_ward.csv")
kbl(budget) %>%
kable_styling(bootstrap_options = c("striped", "hover"))
kbl(comm) %>%
kable_styling(bootstrap_options = c("striped", "hover"))
comm = mutate(commarea_prop = commarea_prop*100)
comm = comm %>% mutate(commarea_prop = commarea_prop*100)
View(comm)
kbl(comm) %>%
kable_styling(bootstrap_options = c("striped", "hover"))
colnames(comm) = c("Community Area", "Count", "% of Respondents")
kbl(comm) %>%
kable_styling(bootstrap_options = c("striped", "hover"))
colnames(comm) = c("Ward", "Count", "% of Respondents")
kbl(comm) %>%
kable_styling(bootstrap_options = c("striped", "hover"))
colnames(ward) = c("Ward", "Count", "% of Respondents")
kbl(ward) %>%
kable_styling(bootstrap_options = c("striped", "hover"))
geo = geo %>% mutate(geo_prop = geo_prop*100)
View(geo)
geo = geo %>% mutate(proportion = proportion*100)
colnames(geo) = c("Geographic Side", "Count", "% of Respondents")
kbl(geo) %>%
kable_styling(bootstrap_options = c("striped", "hover"))
colnames(ward) = c("Ward", "Count", "% of Respondents")
kbl(ward) %>%
kable_styling(bootstrap_options = c("striped", "hover"))
ward = ward %>% mutate(ward_prop = ward_prop*100)
colnames(ward) = c("Ward", "Count", "% of Respondents")
kbl(ward) %>%
kable_styling(bootstrap_options = c("striped", "hover"))
comm <- read.cssv("summary_comm.csv")
geo <- read.csv("summary_geo.csv")
ward <- read.csv("summary_ward.csv")
comm = comm %>% mutate(commarea_prop = commarea_prop*100)
colnames(comm) = c("Community Area", "Count", "% of Respondents")
kbl(comm) %>%
kable_styling(bootstrap_options = c("striped", "hover"))
ward = ward %>% mutate(ward_prop = ward_prop*100)
colnames(ward) = c("Ward", "Count", "% of Respondents")
kbl(ward) %>%
kable_styling(bootstrap_options = c("striped", "hover"))
